{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import *\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "logging.basicConfig(filename = \"../logs/scraper-\" + today + \".log\", level = logging.INFO,\n",
    "                    format = \"[%(levelname)s %(asctime)s] %(message)s\")\n",
    "\n",
    "client = MongoClient()\n",
    "database = client[\"tracking_scraper\"]\n",
    "container_table = database[\"containers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception class and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraperError(Exception):\n",
    "    \"\"\"Custom exception for the Tracking Web Scraper.\"\"\"\n",
    "    pass\n",
    "\n",
    "class TrackingScraperConfig:\n",
    "    \"\"\"Constants and basic configuration for the Tracking Web Scraper.\"\"\"\n",
    "    \n",
    "    # Default executable path for the Google Chrome webdriver\n",
    "    DEFAULT_PATH_CHROME     = \"../driver/chromedriver\"\n",
    "    # Default executable path for the Firefox webdriver\n",
    "    DEFAULT_PATH_FIREFOX    = \"../driver/geckodriver\"\n",
    "    \n",
    "    # Default timeout for short processing, in seconds\n",
    "    DEFAULT_TIMEOUT         = 30\n",
    "    # Default timeout for long processing, in seconds\n",
    "    DEFAULT_TIMEOUT_LONG    = 90\n",
    "    # Default wait for long actions, in seconds\n",
    "    DEFAULT_WAIT_LONG       = 5\n",
    "    # Default wait for short actions, in seconds\n",
    "    DEFAULT_WAIT_SHORT      = 1.5\n",
    "    \n",
    "    # Default value for the key \"required\" in all types\n",
    "    DEFAULT_KEY_REQUIRED    = True\n",
    "    # Default value for the key \"action\" in type \"alert\"\n",
    "    DEFAULT_KEY_ACTION      = True\n",
    "    # Default value for the key \"wait\" in type \"click\"\n",
    "    DEFAULT_KEY_WAIT        = True\n",
    "    # Default value for the key \"clean\" in type \"write\"\n",
    "    DEFAULT_KEY_CLEAN       = False\n",
    "    # Default value for the key \"enter\" in type \"write\"\n",
    "    DEFAULT_KEY_ENTER       = False\n",
    "    # Default value for the key \"overwrite\" in multiple configuration\n",
    "    DEFAULT_KEY_OVERWRITE   = False\n",
    "    # Default value for the key \"frame\" in selector types\n",
    "    DEFAULT_KEY_FRAME       = False\n",
    "    \n",
    "    # Default value for the key \"processed\" in upserting container info\n",
    "    DEFAULT_KEY_PROCESSED   = True\n",
    "    # Default value for the key \"estimated\" in container movements\n",
    "    DEFAULT_KEY_ESTIMATED   = True\n",
    "    \n",
    "    # Default thousand separator symbol\n",
    "    DEFAULT_THOUSAND_SYMBOL = \",\"\n",
    "    # Default datetime locale information\n",
    "    DEFAULT_DATETIME_LOCALE = {\n",
    "        \"hours\": -5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraperSwitcher:\n",
    "    \"\"\"\n",
    "    Switcher for selecting and saving Web elements and subelements in a tracking-related document.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, driver, document, configuration, parent_command, parent_element = None):\n",
    "        self.__driver         = driver\n",
    "        self.__document       = document\n",
    "        self.__configuration  = configuration\n",
    "        self.__parent_command = parent_command\n",
    "        self.__parent_element = driver if parent_element is None else parent_element\n",
    "    \n",
    "    @property\n",
    "    def document(self):\n",
    "        \"\"\"Returns the stored tracking-related dictionary.\"\"\"\n",
    "        return self.__document\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Get Web elements based on the current configuration command, then process or return them\n",
    "        accordingly. Returns True if all commands and subcommands were executed successfully,\n",
    "        False if one command failed, or the list of Web elements if no subcommands were found.\n",
    "        \"\"\"\n",
    "        # Get process type\n",
    "        process_type = self.__parent_command.get(\"type\")\n",
    "        if process_type is None:\n",
    "            raise TrackingScraperError(\"Process type not found\")\n",
    "        logging.info(\"Process type: %s\", process_type)\n",
    "        \n",
    "        # Execute process based on process type\n",
    "        try:\n",
    "            method = getattr(self, \"_process_\" + process_type)\n",
    "            return method()\n",
    "        except AttributeError:\n",
    "            raise TrackingScraperError(\"Process type \" + process_type + \" is not valid\")\n",
    "        except TypeError:\n",
    "            raise TrackingScraperError(\"Process type \" + process_type + \" can't be directly invoked\")\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_id(self):\n",
    "        return self.__process_dom_elements(By.ID)\n",
    "    def _process_class(self):\n",
    "        return self.__process_dom_elements(By.CLASS_NAME)\n",
    "    def _process_css(self):\n",
    "        return self.__process_dom_elements(By.CSS_SELECTOR)\n",
    "    def _process_name(self):\n",
    "        return self.__process_dom_elements(By.NAME)\n",
    "    def _process_tag(self):\n",
    "        return self.__process_dom_elements(By.TAG_NAME)\n",
    "    def _process_xpath(self):\n",
    "        return self.__process_dom_elements(By.XPATH)\n",
    "    \n",
    "    def __process_dom_elements(self, selector_type):\n",
    "        # Get selector\n",
    "        selector = self.__parent_command.get(\"selector\")\n",
    "        if selector is None:\n",
    "            raise TrackingScraperError(\"Selector not found in process by \" + selector_type)\n",
    "        \n",
    "        # Check assertions\n",
    "        assertions = self.__check_assertions(selector_type, selector)\n",
    "        if assertions is True:\n",
    "            logging.info(\"Assertions are correct\")\n",
    "            return True\n",
    "        \n",
    "        # Get DOM elements\n",
    "        dom_elements = self.__parent_element.find_elements(selector_type, selector)\n",
    "        \n",
    "        # Check requirements\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if len(dom_elements) == 0:\n",
    "            logging.info(\"No elements found, using required\")\n",
    "            return not required\n",
    "        \n",
    "        # Get child command list and process them, if possible\n",
    "        commands = self.__parent_command.get(\"commands\")\n",
    "        if isinstance(commands, list):\n",
    "            return self.__process_child_commands(commands, dom_elements)\n",
    "        \n",
    "        # Get a child command for all elements and process them, if possible\n",
    "        child_command = self.__parent_command.get(\"command\")\n",
    "        if isinstance(child_command, dict):\n",
    "            for child_element in dom_elements:\n",
    "                result = self.__generate_child_process(child_command, child_element)\n",
    "                if result is not True:\n",
    "                    return result\n",
    "            return True\n",
    "        \n",
    "        # If no single child command was found, return all DOM elements\n",
    "        logging.info(\"No commands found, return all elements\")\n",
    "        return dom_elements\n",
    "    \n",
    "    def __check_assertions(self, selector_type, selector):\n",
    "        assertion = self.__parent_command.get(\"assert\")\n",
    "        \n",
    "        if isinstance(assertion, bool):\n",
    "            # Set expected conditions depending if we want to switch to a frame or not\n",
    "            frame = self.__parent_command.get(\"frame\", TrackingScraperConfig.DEFAULT_KEY_FRAME)\n",
    "            if frame:\n",
    "                conditions = EC.frame_to_be_available_and_switch_to_it((selector_type, selector))\n",
    "            else:\n",
    "                conditions = EC.presence_of_all_elements_located((selector_type, selector))\n",
    "            \n",
    "            # Prepare waiter\n",
    "            waiter = WebDriverWait(self.__driver, TrackingScraperConfig.DEFAULT_TIMEOUT)\n",
    "            \n",
    "            if assertion:\n",
    "                # Assert at least one element found\n",
    "                try:\n",
    "                    waiter.until(conditions)\n",
    "                except TimeoutException:\n",
    "                    raise TrackingScraperError(\"Assertion error: Elements unexpectedly not found\")\n",
    "            else:\n",
    "                # Assert no elements found\n",
    "                try:\n",
    "                    waiter.until_not(conditions)\n",
    "                except TimeoutException:\n",
    "                    raise TrackingScraperError(\"Assertion error: Elements unexpectedly found\")\n",
    "            \n",
    "            # Wait a little bit and return\n",
    "            time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "            return True\n",
    "        \n",
    "        logging.info(\"Assertions not found, selector: %s by %s\", selector, selector_type)\n",
    "        return False\n",
    "    \n",
    "    def __process_child_commands(self, commands, elements):\n",
    "        for child_command in commands:\n",
    "            # Get index\n",
    "            index = child_command.get(\"index\")\n",
    "            if index is None:\n",
    "                raise TrackingScraperError(\"Child index command not found\")\n",
    "            \n",
    "            # Check requirements\n",
    "            if index >= len(elements):\n",
    "                logging.info(\"Child element at index %d, using required\", index)\n",
    "                return not child_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "            \n",
    "            # Process child element at specified index\n",
    "            logging.info(\"Child index: %d\", index)\n",
    "            result = self.__generate_child_process(child_command, elements[index])\n",
    "            \n",
    "            # If no subelements were found, return that element or element list\n",
    "            # If a minor error occured (e.g. element not found), return False\n",
    "            if result is not True:\n",
    "                return result\n",
    "        \n",
    "        # If everything was fine, return True\n",
    "        return True\n",
    "    \n",
    "    def __generate_child_process(self, child_command, child_element):\n",
    "        return TrackingScraperSwitcher(self.__driver, self.__document, self.__configuration,\n",
    "                                       child_command, child_element).process()\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_split(self):\n",
    "        # Get text to split\n",
    "        parent_text = self.__get_parent_text()\n",
    "        \n",
    "        # Get text separator\n",
    "        delimiter = self.__parent_command.get(\"delimiter\")\n",
    "        if delimiter is None:\n",
    "            raise TrackingScraperError(\"No separator found\")\n",
    "        \n",
    "        # Split text\n",
    "        elements = parent_text.split(delimiter)\n",
    "        \n",
    "        # Get child command list and process them, if possible\n",
    "        commands = self.__parent_command.get(\"commands\")\n",
    "        if isinstance(commands, list):\n",
    "            return self.__process_child_commands(commands, elements)\n",
    "        \n",
    "        # If no single child command was found, return split list\n",
    "        return elements\n",
    "    \n",
    "    def __get_parent_text(self):\n",
    "        parent_text = self.__parent_element\n",
    "        try:\n",
    "            return parent_text.text.strip() # value is a DOM element, we need its inner text\n",
    "        except AttributeError:\n",
    "            return parent_text.strip() # value is already a string\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_regex(self):\n",
    "        # Get text\n",
    "        text = self.__get_parent_text()\n",
    "        \n",
    "        # Get regular expression pattern\n",
    "        pattern = self.__parent_command.get(\"pattern\")\n",
    "        if pattern is None:\n",
    "            raise TrackingScraperError(\"No regular expression found\")\n",
    "        \n",
    "        # Match expression with text\n",
    "        regex    = re.search(pattern, text)\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if regex is None:\n",
    "            logging.info(\"Regular expression does not match text, using required\")\n",
    "            return not required\n",
    "        \n",
    "        # Get list of matched elements\n",
    "        elements = list(regex.groups())\n",
    "        \n",
    "        # Get child command list and process them, if possible\n",
    "        commands = self.__parent_command.get(\"commands\")\n",
    "        if isinstance(commands, list):\n",
    "            return self.__process_child_commands(commands, elements)\n",
    "        \n",
    "        # If no single child command was found, return list of matched elements\n",
    "        return elements\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_save(self):\n",
    "        attribute = self.__parent_command.get(\"key\")\n",
    "        if attribute is None:\n",
    "            raise TrackingScraperError(\"Save key not found\")\n",
    "        \n",
    "        # If a value was already defined, save it and exit\n",
    "        value = self.__parent_command.get(\"value\")\n",
    "        if value is not None:\n",
    "            self.__document[attribute] = value\n",
    "            return True\n",
    "        \n",
    "        # Get text to be saved, and verify if it's not empty\n",
    "        value    = self.__get_parent_text()\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if len(value) == 0:\n",
    "            logging.info(\"Text to save is empty, using required\")\n",
    "            return not required\n",
    "        \n",
    "        # Format type if necessary\n",
    "        format_type = self.__parent_command.get(\"format\")\n",
    "        if format_type is not None:\n",
    "            value = TrackingScraperConverter(value, format_type, self.__configuration).convert()\n",
    "            # If a value already exists in the attribute and it's a datetime object, join them\n",
    "            if self.__join_datetimes_if_possible(attribute, value):\n",
    "                return True\n",
    "            \n",
    "        # Save according to parent key and formatting value\n",
    "        self.__document[attribute] = value\n",
    "        return True\n",
    "    \n",
    "    def __join_datetimes_if_possible(self, attribute, new_value):\n",
    "        # Check if attribute exists\n",
    "        if attribute not in self.__document:\n",
    "            return False\n",
    "        \n",
    "        # Get value from attribute\n",
    "        old_value = self.__document[attribute]\n",
    "        \n",
    "        # Check if old value is a date and new value is a time\n",
    "        if isinstance(old_value, datetime.datetime) and isinstance(new_value, datetime.time):\n",
    "            self.__document[attribute] = datetime.datetime.combine(old_value.date(), new_value)\n",
    "            return True\n",
    "        \n",
    "        # Return False if nothing was found\n",
    "        return False\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_attr(self):\n",
    "        # Get attribute name\n",
    "        attribute_name = self.__parent_command.get(\"name\")\n",
    "        if attribute_name is None:\n",
    "            raise TrackingScraperError(\"Attribute name not found\")\n",
    "        \n",
    "        # Get attribute value from parent element\n",
    "        attribute = self.__parent_element.get_attribute(attribute_name)\n",
    "        \n",
    "        # Get child command, if none found, return attribute\n",
    "        child_command = self.__parent_command.get(\"command\")\n",
    "        if child_command is not None:\n",
    "            logging.info(\"ATTRIBUTE - Child command found\")\n",
    "            return TrackingScraperSwitcher(self.__driver, self.__document, self.__configuration,\n",
    "                                           child_command, attribute).process()\n",
    "        print(attribute)\n",
    "        logging.info(\"ATTRIBUTE - No child command found\")\n",
    "        return attribute\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_compare(self):\n",
    "        # Get text to compare\n",
    "        text = self.__get_parent_text()\n",
    "        \n",
    "        # Get values to compare\n",
    "        values = self.__parent_command.get(\"values\")\n",
    "        if values is None:\n",
    "            raise TrackingScraperError(\"Values to compare not found\")\n",
    "        \n",
    "        # Check if text equals to value, or if it is in value list, then act accordingly\n",
    "        if text in values:\n",
    "            commands = self.__parent_command.get(\"success\")\n",
    "            return self.__process_compare_commands(commands, \"Success\")\n",
    "        else:\n",
    "            commands = self.__parent_command.get(\"failure\")\n",
    "            return self.__process_compare_commands(commands, \"Failure\")\n",
    "    \n",
    "    def __process_compare_commands(self, commands, compare_result):\n",
    "        # Check requirements\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if commands is None:\n",
    "            logging.info(compare_result + \" commands not found, resorting to required\")\n",
    "            return not required\n",
    "        \n",
    "        # Process child commands\n",
    "        for child_command in commands:\n",
    "            result = self.__generate_child_process(child_command, self.__parent_element)\n",
    "            if result is not True:\n",
    "                return result\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_write(self):\n",
    "        # Get value\n",
    "        value = self.__parent_command.get(\"value\")\n",
    "        if value is None:\n",
    "            # Get value from attribute\n",
    "            attribute = self.__parent_command.get(\"attribute\")\n",
    "            if attribute is None:\n",
    "                raise TrackingScraperError(\"No value or attribute to use as input\")\n",
    "            value = self.__document.get(attribute)\n",
    "        \n",
    "        try:\n",
    "            # Clear element if specified\n",
    "            if self.__parent_command.get(\"clean\", TrackingScraperConfig.DEFAULT_KEY_CLEAN):\n",
    "                self.__parent_element.clear()\n",
    "            # Write value\n",
    "            self.__parent_element.send_keys(value)\n",
    "            # Send enter if specified\n",
    "            if self.__parent_command.get(\"enter\", TrackingScraperConfig.DEFAULT_KEY_ENTER):\n",
    "                self.__parent_element.send_keys(Keys.ENTER)\n",
    "        except AttributeError:\n",
    "            raise TrackingScraperError(\"Element is not interactable (attribute)\")\n",
    "        except ElementNotInteractableException:\n",
    "            raise TrackingScraperError(\"Element is not interactable (selenium)\")\n",
    "        \n",
    "        # Return True to indicate everything is OK\n",
    "        time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_alert(self):\n",
    "        assertion = self.__parent_command.get(\"assertion\")\n",
    "        # TODO: Usar waits\n",
    "        try:\n",
    "            # Try to switch to alert\n",
    "            alert = self.__driver.switch_to.alert\n",
    "            if assertion is False:\n",
    "                raise TrackingScraperError(\"Assertion failed: Alert unexpectedly found\")\n",
    "            # Accept or dismiss action depending on command\n",
    "            if self.__parent_command.get(\"action\", TrackingScraperConfig.DEFAULT_KEY_ACTION):\n",
    "                alert.accept()\n",
    "            else:\n",
    "                alert.dismiss()\n",
    "        except NoAlertPresentException:\n",
    "            if assertion is True:\n",
    "                raise TrackingScraperError(\"Assertion failed: Alert unexpectedly not found\")\n",
    "        \n",
    "        # Return True to indicate everything is OK\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_click(self):\n",
    "        # Check requirements\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if not self.__parent_element.is_displayed():\n",
    "            return not required\n",
    "        if not self.__parent_element.is_enabled():\n",
    "            return not required\n",
    "        \n",
    "        try:\n",
    "            # Try to click the element\n",
    "            self.__parent_element.click()\n",
    "            \n",
    "            # Wait 2 or 5 seconds depending on \"wait\" attribute\n",
    "            wait_time = self.__parent_command.get(\"wait\", TrackingScraperConfig.DEFAULT_KEY_WAIT)\n",
    "            if wait_time:\n",
    "                time.sleep(TrackingScraperConfig.DEFAULT_WAIT_LONG)\n",
    "            else:\n",
    "                time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "                \n",
    "            # Return True to indicate everything is OK\n",
    "            return True\n",
    "        except ElementNotInteractableException:\n",
    "            return not required\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_ocr(self):\n",
    "        length = self.__parent_command.get(\"length\")\n",
    "        if length is None:\n",
    "            raise TrackingScraperError(\"Text length not defined\")\n",
    "        \n",
    "        # Request text\n",
    "        text = input(\"Enter captcha text: \")\n",
    "        if len(text) != length:\n",
    "            raise TrackingScraperError(\"Text is not \" + str(length) + \" characters long\")\n",
    "        \n",
    "        # Save to attribute\n",
    "        self.__document[\"ocr\"] = text\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraperConverter:\n",
    "    \"\"\"Utility class to convert text to other Python types.\"\"\"\n",
    "    \n",
    "    def __init__(self, raw_text, format_type, configuration):\n",
    "        self.__raw_text      = raw_text\n",
    "        self.__format_type   = format_type\n",
    "        self.__configuration = configuration\n",
    "    \n",
    "    def convert(self):\n",
    "        \"\"\"Try to convert to the desired type, if none found, return text as-is.\"\"\"\n",
    "        try:\n",
    "            method = getattr(self, \"_convert_to_\" + self.__format_type)\n",
    "            return method()\n",
    "        except AttributeError:\n",
    "            logging.info(\"Convertion to \" + self.__format_type + \" not supported, resorting to text\")\n",
    "            return self.__raw_text\n",
    "        except TypeError:\n",
    "            raise TrackingScraperError(\"Convertion to \" + self.__format_type + \" cannot be invoked\")\n",
    "    \n",
    "    def _convert_to_int(self):\n",
    "        \"\"\"Convert text to an integer.\"\"\"\n",
    "        try:\n",
    "            return int(self.__raw_text.replace(TrackingScraperConfig.DEFAULT_THOUSAND_SYMBOL, \"\"))\n",
    "        except ValueError:\n",
    "            logging.info(\"Convertion to integer failed, resorting to text\")\n",
    "            return self.__raw_text\n",
    "    \n",
    "    def _convert_to_float(self):\n",
    "        \"\"\"Convert text to a double-precision floating-point number.\"\"\"\n",
    "        try:\n",
    "            return float(self.__raw_text.replace(TrackingScraperConfig.DEFAULT_THOUSAND_SYMBOL, \"\"))\n",
    "        except ValueError:\n",
    "            logging.info(\"Convertion to float failed, resorting to text\")\n",
    "            return self.__raw_text\n",
    "    \n",
    "    def _convert_to_double(self):\n",
    "        # Alias for self._convert_to_float().\n",
    "        return self._convert_to_float()\n",
    "    \n",
    "    def _convert_to_date(self):\n",
    "        \"\"\"Convert text to a Python datetime object.\"\"\"\n",
    "        # Get datetime patterns\n",
    "        try:\n",
    "            patterns = self.__configuration[\"general\"][\"date_formats\"]\n",
    "        except KeyError:\n",
    "            logging.info(\"Datetime patterns not found, resorting to text\")\n",
    "            return self.__raw_text\n",
    "        \n",
    "        # Try each pattern until it matches one\n",
    "        for pattern in patterns:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(self.__raw_text, pattern)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # If none of the patterns matched, return text as-is\n",
    "        logging.info(\"None of the patterns matched, resorting to text\")\n",
    "        return self.__raw_text\n",
    "    \n",
    "    def _convert_to_datetime(self):\n",
    "        return self._convert_to_date()\n",
    "    \n",
    "    def _convert_to_time(self):\n",
    "        \"\"\"Convert text to a Python time object.\"\"\"\n",
    "        value = self._convert_to_date()\n",
    "        if isinstance(value, datetime.datetime):\n",
    "            return value.time()\n",
    "        return value\n",
    "    \n",
    "    def _convert_to_datelocal(self):\n",
    "        \"\"\"Convert text to a Python datetime object taking the defined locale into account.\"\"\"\n",
    "        value = self._convert_to_date()\n",
    "        if isinstance(value, datetime.datetime):\n",
    "            return value - datetime.timedelta(**TrackingScraperConfig.DEFAULT_DATETIME_LOCALE)\n",
    "        return value\n",
    "    \n",
    "    def _convert_to_timelocal(self):\n",
    "        \"\"\"Convert text to a Python time object taking the defined locale into account.\"\"\"\n",
    "        value = self._convert_to_datelocal()\n",
    "        if isinstance(value, datetime.datetime):\n",
    "            return value.time()\n",
    "        return value\n",
    "    \n",
    "    def _convert_to_status(self):\n",
    "        \"\"\"Convert text to a tracking status based on the configuration for translation.\"\"\"\n",
    "        # TO-DO\n",
    "        return self.__raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main scraper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraper:\n",
    "    \"\"\"Main class for the Tracking Web Scraper.\"\"\"\n",
    "    \n",
    "    def __init__(self, driver, database, document):\n",
    "        self.__driver   = driver\n",
    "        self.__database = database\n",
    "        self.__document = document\n",
    "        \n",
    "        # Get configuration file\n",
    "        try:\n",
    "            with open(\"../config/\" + self.__document[\"carrier\"] + \".json\") as file:\n",
    "                self.__configuration = json.load(file)\n",
    "        except KeyError:\n",
    "            raise TrackingScraperError(\"Carrier not found\")\n",
    "        except FileNotFoundError:\n",
    "            raise TrackingScraperError(\"Configuration file not found\")\n",
    "        \n",
    "        # Get general configuration\n",
    "        if \"general\" not in self.__configuration:\n",
    "            raise TrackingScraperError(\"General configuration information not found\")\n",
    "        \n",
    "        # Get single and multiple tables\n",
    "        self.__single_table, self.__single_query     = self._get_database_config(database, \"single\")\n",
    "        self.__multiple_table, self.__multiple_query = self._get_database_config(database, \"multiple\")\n",
    "    \n",
    "    def _get_database_config(self, database, config_type):\n",
    "        # Get configuration\n",
    "        collection_configuration = self.__configuration[\"general\"].get(config_type)\n",
    "        if collection_configuration is None:\n",
    "            return None\n",
    "\n",
    "        # Get collection name\n",
    "        table_name = collection_configuration.get(\"table\")\n",
    "        if table_name is None:\n",
    "            raise TrackingScraperError(\"Table name for \" + config_type + \" entries not found\")\n",
    "        \n",
    "        # Get collection query\n",
    "        table_query_keys = collection_configuration.get(\"query\")\n",
    "        if not isinstance(table_query_keys, list):\n",
    "            table_query_keys = []\n",
    "        \n",
    "        # Return database and query keys\n",
    "        return database[table_name], table_query_keys\n",
    "        \n",
    "    @property\n",
    "    def document(self):\n",
    "        \"\"\"Returns the container information.\"\"\"\n",
    "        return self.__document\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def execute(self):\n",
    "        \"\"\"Execute commands.\"\"\"\n",
    "        \n",
    "        parent_result   = False\n",
    "        input_result    = False\n",
    "        single_result   = False\n",
    "        multiple_result = False\n",
    "        \n",
    "        try:\n",
    "            start = self._go_to_url()\n",
    "            while True:\n",
    "                # Check if we're still on time\n",
    "                end = time.time()\n",
    "                if (end - start) > TrackingScraperConfig.DEFAULT_TIMEOUT:\n",
    "                    raise TrackingScraperError(\"Timeout exceeded, scraping was unsuccessful\")\n",
    "                \n",
    "                # Execute input\n",
    "                input_result = self._execute_commands(input_result, \"input\")\n",
    "                if input_result is not True:\n",
    "                    logging.info(\"Input execution was unsuccessful, retrying...\")\n",
    "                    continue\n",
    "                \n",
    "                # Execute single output\n",
    "                single_result = self._execute_commands(single_result, \"single\")\n",
    "                if single_result is not True:\n",
    "                    logging.info(\"Single output execution was unsuccessful, retrying...\")\n",
    "                    continue\n",
    "                \n",
    "                # Execute multiple output\n",
    "                multiple_result = self._execute_multiple_output(multiple_result)\n",
    "                if multiple_result is not True:\n",
    "                    logging.info(\"Multiple output execution was unsuccessful, retrying...\")\n",
    "                    continue\n",
    "                \n",
    "                # Finish execution and save elements\n",
    "                parent_result = self._finish_execution()\n",
    "                time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "                break\n",
    "        except TrackingScraperError:\n",
    "            logging.exception(\"Exception ocurred\")\n",
    "        except Exception:\n",
    "            logging.exception(\"Unknown exception ocurred\")\n",
    "        finally:\n",
    "            return parent_result\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _go_to_url(self):\n",
    "        # Check if general configuration is declared\n",
    "        general_config = self.__configuration.get(\"general\")\n",
    "        if general_config is None:\n",
    "            raise TrackingScraperError(\"Configuration information not found\")\n",
    "        \n",
    "        # Get configuration URL\n",
    "        link = self.__configuration[\"general\"].get(\"url\")\n",
    "        if link is None:\n",
    "            raise TrackingScraperError(\"Configuration URL could not be found\")\n",
    "        \n",
    "        # Go to desired URL\n",
    "        try:\n",
    "            self.__driver.get(link.format(**self.__document))\n",
    "            time.sleep(TrackingScraperConfig.DEFAULT_WAIT_LONG)\n",
    "        except TimeoutException:\n",
    "            raise TrackingScraperError(\"Error loading Web page, timeout exceeded\")\n",
    "        \n",
    "        # Start time counting\n",
    "        return time.time()\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _execute_commands(self, parent_result, key):\n",
    "        # Check if commands were already executed\n",
    "        if parent_result is True:\n",
    "            return True\n",
    "        \n",
    "        # Get commands, if none found, return True\n",
    "        commands = self.__configuration.get(key)\n",
    "        if commands is None:\n",
    "            return True\n",
    "        \n",
    "        # Process commands\n",
    "        for command in commands:\n",
    "            result = TrackingScraperSwitcher(self.__driver, self.__document, self.__configuration,\n",
    "                                             command).process()\n",
    "            if result is not True:\n",
    "                return False\n",
    "        \n",
    "        # Return True if everything was OK\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _execute_multiple_output(self, multiple_result):\n",
    "        if multiple_result is True:\n",
    "            return True\n",
    "        \n",
    "        # Get multiple command, if none found, return True\n",
    "        multiple_command = self.__configuration.get(\"multiple\")\n",
    "        if multiple_command is None:\n",
    "            return True\n",
    "        \n",
    "        # Get configuration key\n",
    "        multiple_configuration = self.__configuration[\"general\"].get(\"multiple\")\n",
    "        if multiple_configuration is None:\n",
    "            return True\n",
    "        \n",
    "        # Create multiple document based on single query items\n",
    "        multiple_document = self._create_query_document(self.__document, self.__single_query)\n",
    "        # Overwrite previous tracking items, if necessary\n",
    "        if multiple_command.get(\"overwrite\", TrackingScraperConfig.DEFAULT_KEY_OVERWRITE):\n",
    "            self.__single_table.delete_many(multiple_document)\n",
    "        \n",
    "        # Generate and process multiple documents\n",
    "        estimated = multiple_configuration.get(\"estimated\", TrackingScraperConfig.DEFAULT_KEY_ESTIMATED)\n",
    "        multiple_document[\"estimated\"] = estimated\n",
    "        return self.__process_multiple_elements(multiple_command, multiple_document, self.__driver)\n",
    "    \n",
    "    def __process_multiple_elements(self, multiple_command, multiple_document, previous_element):\n",
    "        # Get single subcommands\n",
    "        multiple_single_commands = multiple_command.get(\"single\")\n",
    "        if not isinstance(multiple_single_commands, list):\n",
    "            raise TrackingScraperError(\"Multiple command must have single commands key\")\n",
    "        \n",
    "        # Get command to find parents, if none found, use driver to extract single commands\n",
    "        multiple_parents = multiple_command.get(\"parents\")\n",
    "        if multiple_parents is None:\n",
    "            multiple_elements = [previous_element]\n",
    "        else:\n",
    "            multiple_elements = TrackingScraperSwitcher(self.__driver, {}, self.__configuration,\n",
    "                                                        multiple_parents, previous_element).process()\n",
    "            if not isinstance(multiple_elements, list):\n",
    "                raise TrackingScraperError(\"Parent elements must be a list of web elements\")\n",
    "        \n",
    "        # Get multiple subcomamnd\n",
    "        multiple_multiple_command = multiple_command.get(\"multiple\")\n",
    "        \n",
    "        # Process every single command for every multiple element\n",
    "        for multiple_subelement in multiple_elements:\n",
    "            subdocument = dict(multiple_document)\n",
    "            for single_command in multiple_single_commands:\n",
    "                single_result = TrackingScraperSwitcher(self.__driver, subdocument,\n",
    "                                                        self.__configuration, single_command,\n",
    "                                                        multiple_subelement).process()\n",
    "                if single_result is not True:\n",
    "                    logging.info(\"Multiple: single subcommand failed\")\n",
    "                    return False\n",
    "            \n",
    "            # Check if multiple subcommand exists, if it doesn't, save and continue.\n",
    "            if multiple_multiple_command is None:\n",
    "                self._insert_or_update(subdocument, self.__multiple_table, self.__multiple_query)\n",
    "                continue\n",
    "            \n",
    "            # If it exists, copy result document and iterate these new multiple elements with it\n",
    "            multiple_result = self.__process_multiple_elements(multiple_multiple_command,\n",
    "                                                               subdocument, multiple_subelement)\n",
    "            if multiple_result is not True:\n",
    "                logging.info(\"Multiple: multiple subcommand failed\")\n",
    "                return False\n",
    "        \n",
    "        # Return True to notify everything is OK\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _finish_execution(self):\n",
    "        # Get configuration for single element\n",
    "        single_config = self.__configuration[\"general\"].get(\"single\")\n",
    "        if single_config is None:\n",
    "            return True\n",
    "        \n",
    "        # Get processed value to save\n",
    "        processed_value = single_config.get(\"processed\", TrackingScraperConfig.DEFAULT_KEY_PROCESSED)\n",
    "        self.__document[\"processed\"] = processed_value\n",
    "        \n",
    "        # Get collection and upsert container\n",
    "        return self._insert_or_update(self.__document, self.__single_table, self.__single_query)\n",
    "    \n",
    "    def _insert_or_update(self, document, collection, query_keys):\n",
    "        # Create shallow copy of document, with specified keys, for query\n",
    "        query_document = self._create_query_document(document, query_keys)\n",
    "        logging.info(\"query document: %s\", query_document)\n",
    "        \n",
    "        # Try to update\n",
    "        document[\"updated_at\"] = datetime.datetime.utcnow()\n",
    "        result = collection.update_one(query_document, {\"$set\": document})\n",
    "        \n",
    "        if result.matched_count > 0:\n",
    "            logging.info(\"Container updated: %s\", query_document)\n",
    "            return True\n",
    "\n",
    "        # If update was unsuccessful, insert document\n",
    "        document[\"created_at\"] = datetime.datetime.utcnow()\n",
    "        document[\"updated_at\"] = None\n",
    "        \n",
    "        result = collection.insert_one(document)\n",
    "        logging.info(\"Container insert: %s\", query_document)\n",
    "        return True\n",
    "    \n",
    "    def _create_query_document(self, document, query_keys):\n",
    "        query_document = {}\n",
    "        for key in query_keys:\n",
    "            query_document[key] = document.get(key)\n",
    "        return query_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas unitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncontainers = [\\n    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"1\", \"container\": \"FSCU5670046\", \"carrier\": \"Hapag-Lloyd\" },\\n    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"2\", \"container\": \"HLXU5183586\", \"carrier\": \"Hapag-Lloyd\" },\\n    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"3\", \"container\": \"MAEU6835658\", \"carrier\": \"Maersk\" },\\n    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"4\", \"container\": \"EGSU9089973\", \"carrier\": \"Evergreen\" },\\n    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"5\", \"container\": \"TEMU3806660\", \"carrier\": \"Textainer\" }]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "containers = [\n",
    "    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"1\", \"container\": \"FSCU5670046\", \"carrier\": \"Hapag-Lloyd\" },\n",
    "    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"2\", \"container\": \"HLXU5183586\", \"carrier\": \"Hapag-Lloyd\" },\n",
    "    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"3\", \"container\": \"MAEU6835658\", \"carrier\": \"Maersk\" },\n",
    "    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"4\", \"container\": \"EGSU9089973\", \"carrier\": \"Evergreen\" },\n",
    "    { \"year\": \"2019\", \"manifest\": \"TEST\", \"detail\": \"5\", \"container\": \"TEMU3806660\", \"carrier\": \"Textainer\" }]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7595"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containers = []\n",
    "query = {\n",
    "    \"carrier\": \"Textainer\",\n",
    "    \"processed\": False\n",
    "}\n",
    "for container in container_table.find(query).sort(\"_id\", -1):\n",
    "    containers.append(container)\n",
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_counter = 0\n",
    "start = time.time()\n",
    "driver = webdriver.Chrome(executable_path = TrackingScraperConfig.DEFAULT_PATH_CHROME)\n",
    "for container in containers:\n",
    "    if fail_counter >= 10:\n",
    "        logging.error(\"Too much failures, aborting\")\n",
    "        break\n",
    "    cont_start = time.time()\n",
    "    try:\n",
    "        scraper = TrackingScraper(driver, database, container)\n",
    "        if not scraper.execute():\n",
    "            fail_counter = fail_counter + 1\n",
    "            logging.error(\"Scraper for container %s unsuccessful\", container[\"container\"])\n",
    "    except TrackingScraperError as ex:\n",
    "        fail_counter = fail_counter + 1\n",
    "        logging.error(\"Error extracting container information: %s\", str(ex))\n",
    "        continue\n",
    "    except Exception:\n",
    "        fail_counter = fail_counter + 1\n",
    "        logging.exception(\"Unknown exception ocurred when creating or executing scraper\")\n",
    "        break\n",
    "    finally:\n",
    "        cont_end = time.time()\n",
    "        print(\"Container time:\", cont_end - cont_start, \"seconds\")\n",
    "# input(\"Press Enter to quit\")\n",
    "driver.close()\n",
    "end = time.time()\n",
    "print(\"Total time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
