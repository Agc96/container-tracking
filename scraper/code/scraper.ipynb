{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import *\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = \"../logs/scraper-20190325.log\", level = logging.INFO,\n",
    "                    format = \"[%(levelname)s %(asctime)s] %(message)s\")\n",
    "\n",
    "client = MongoClient()\n",
    "database = client[\"tracking_scraper\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception class and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraperError(Exception):\n",
    "    \"\"\"Custom exception for the Tracking Web Scraper.\"\"\"\n",
    "    pass\n",
    "\n",
    "class TrackingScraperConfig:\n",
    "    \"\"\"Constants and basic configuration for the Tracking Web Scraper.\"\"\"\n",
    "    \n",
    "    # Default timeout, in seconds\n",
    "    DEFAULT_TIMEOUT         = 60\n",
    "    # Default wait for long actions, in seconds\n",
    "    DEFAULT_WAIT_LONG       = 5\n",
    "    # Default wait for short actions, in seconds\n",
    "    DEFAULT_WAIT_SHORT      = 1.5\n",
    "    \n",
    "    # Default value for the key \"required\" in all types\n",
    "    DEFAULT_KEY_REQUIRED    = True\n",
    "    # Default value for the key \"action\" in type \"alert\"\n",
    "    DEFAULT_KEY_ACTION      = True\n",
    "    # Default value for the key \"wait\" in type \"click\"\n",
    "    DEFAULT_KEY_WAIT        = True\n",
    "    # Default value for the key \"clean\" in type \"write\"\n",
    "    DEFAULT_KEY_CLEAN       = False\n",
    "    # Default value for the key \"enter\" in type \"write\"\n",
    "    DEFAULT_KEY_ENTER       = False\n",
    "    \n",
    "    # Default thousand separator symbol\n",
    "    DEFAULT_THOUSAND_SYMBOL = \",\"\n",
    "    # Default datetime locale information\n",
    "    DEFAULT_DATETIME_LOCALE = {\n",
    "        \"hours\": -5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraperSwitcher:\n",
    "    \"\"\"\n",
    "    Switcher for selecting and saving Web elements and subelements in a tracking-related document.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, driver, document, configuration, parent_command, parent_element = None):\n",
    "        self.__driver         = driver\n",
    "        self.__document       = document\n",
    "        self.__configuration  = configuration\n",
    "        self.__parent_command = parent_command\n",
    "        self.__parent_element = driver if parent_element is None else parent_element\n",
    "    \n",
    "    @property\n",
    "    def document(self):\n",
    "        \"\"\"Returns the stored tracking-related dictionary.\"\"\"\n",
    "        return self.__document\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Get Web elements based on the current configuration command, then process or return them\n",
    "        accordingly. Returns True if all commands and subcommands were executed successfully,\n",
    "        False if one command failed, or the list of Web elements if no subcommands were found.\n",
    "        \"\"\"\n",
    "        # Get process type\n",
    "        process_type = self.__parent_command.get(\"type\")\n",
    "        if process_type is None:\n",
    "            raise TrackingScraperError(\"Process type not found\")\n",
    "        logging.info(\"Process type: %s\", process_type)\n",
    "        \n",
    "        # Execute process based on process type\n",
    "        try:\n",
    "            method = getattr(self, \"_process_\" + process_type)\n",
    "            return method()\n",
    "        except AttributeError:\n",
    "            raise TrackingScraperError(\"Process type \" + process_type + \" is not valid\")\n",
    "        except TypeError:\n",
    "            raise TrackingScraperError(\"Process type \" + process_type + \" can't be directly invoked\")\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_id(self):\n",
    "        return self.__process_dom_elements(By.ID)\n",
    "    def _process_class(self):\n",
    "        return self.__process_dom_elements(By.CLASS_NAME)\n",
    "    def _process_css(self):\n",
    "        return self.__process_dom_elements(By.CSS_SELECTOR)\n",
    "    def _process_name(self):\n",
    "        return self.__process_dom_elements(By.NAME)\n",
    "    def _process_tag(self):\n",
    "        return self.__process_dom_elements(By.TAG_NAME)\n",
    "    def _process_xpath(self):\n",
    "        return self.__process_dom_elements(By.XPATH)\n",
    "    \n",
    "    def __process_dom_elements(self, selector_type):\n",
    "        # Get selector\n",
    "        selector = self.__parent_command.get(\"selector\")\n",
    "        if selector is None:\n",
    "            raise TrackingScraperError(\"Selector not found in process by \" + selector_type)\n",
    "        \n",
    "        # Check assertions\n",
    "        assertions = self.__check_assertions(selector_type, selector)\n",
    "        if assertions is True:\n",
    "            return True\n",
    "        \n",
    "        # Get DOM elements\n",
    "        dom_elements = self.__parent_element.find_elements(selector_type, selector)\n",
    "        \n",
    "        # Check requirements\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if len(dom_elements) == 0:\n",
    "            logging.info(\"No elements found, using required\")\n",
    "            return not required\n",
    "        \n",
    "        # Get child command list and process them, if possible\n",
    "        commands = self.__parent_command.get(\"commands\")\n",
    "        if isinstance(commands, list):\n",
    "            return self.__process_child_commands(commands, dom_elements)\n",
    "        \n",
    "        # Get a child command for all elements and process them, if possible\n",
    "        child_command = self.__parent_command.get(\"command\")\n",
    "        if child_command is not None:\n",
    "            for child_element in dom_elements:\n",
    "                result = self.__generate_child_process(child_command, child_element)\n",
    "                if result is not True:\n",
    "                    return result\n",
    "            return True\n",
    "        \n",
    "        # If no single child command was found, return all DOM elements\n",
    "        logging.info(\"No commands found, return\")\n",
    "        return dom_elements\n",
    "    \n",
    "    def __check_assertions(self):\n",
    "        assertion = self.__parent_command.get(\"assert\")\n",
    "        \n",
    "        # Assert at least one element found\n",
    "        if assertion is True:\n",
    "            try:\n",
    "                WebDriverWait(self.__driver, TrackingScraperConfig.DEFAULT_TIMEOUT,\n",
    "                              TrackingScraperConfig.DEFAULT_WAIT_SHORT).until(\n",
    "                    EC.presence_of_all_elements_located((selector_type, selector)))\n",
    "            except TimeoutException:\n",
    "                raise TrackingScraperError(\"Assertion error: Elements unexpectedly not found\")\n",
    "            \n",
    "            time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "            return True\n",
    "        \n",
    "        # Assert no elements found\n",
    "        if assertion is False:\n",
    "            try:\n",
    "                WebDriverWait(self.__driver, TrackingScraperConfig.DEFAULT_TIMEOUT,\n",
    "                              TrackingScraperConfig.DEFAULT_WAIT_SHORT).until_not(\n",
    "                    EC.presence_of_all_elements_located((selector_type, selector)))\n",
    "            except TimeoutException:\n",
    "                raise TrackingScraperError(\"Assertion error: Elements unexpectedly found\")\n",
    "            \n",
    "            time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def __process_child_commands(self, commands, elements):\n",
    "        for child_command in commands:\n",
    "            # Get index\n",
    "            index = child_command.get(\"index\")\n",
    "            if index is None:\n",
    "                raise TrackingScraperError(\"Child index command not found\")\n",
    "            \n",
    "            # Check requirements\n",
    "            if index >= len(elements):\n",
    "                logging.info(\"Child element at index \" + index + \", using required\")\n",
    "                return not child_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "            \n",
    "            # Process child element at specified index\n",
    "            logging.info(\"Child index: %d\", index)\n",
    "            result = self.__generate_child_process(child_command, elements[index])\n",
    "            \n",
    "            # If no subelements were found, return that element or element list\n",
    "            # If a minor error occured (e.g. element not found), return False\n",
    "            if result is not True:\n",
    "                return result\n",
    "        \n",
    "        # If everything was fine, return True\n",
    "        return True\n",
    "    \n",
    "    def __generate_child_process(self, child_command, child_element):\n",
    "        return TrackingScraperSwitcher(self.__driver, self.__document, self.__configuration,\n",
    "                                       child_command, child_element).process()\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_split(self):\n",
    "        # Get text to split\n",
    "        parent_text = self.__get_parent_text()\n",
    "        \n",
    "        # Get text separator\n",
    "        delimiter = self.__parent_command.get(\"delimiter\")\n",
    "        if delimiter is None:\n",
    "            raise TrackingScraperError(\"No separator found\")\n",
    "        \n",
    "        # Split text\n",
    "        elements = parent_text.split(delimiter)\n",
    "        \n",
    "        # Get child command list and process them, if possible\n",
    "        commands = self.__parent_command.get(\"commands\")\n",
    "        if isinstance(commands, list):\n",
    "            return self.__process_child_commands(commands, elements)\n",
    "        \n",
    "        # If no single child command was found, return split list\n",
    "        return elements\n",
    "    \n",
    "    def __get_parent_text(self):\n",
    "        parent_text = self.__parent_element\n",
    "        try:\n",
    "            return parent_text.text.strip() # value is a DOM element, we need its inner text\n",
    "        except AttributeError:\n",
    "            return parent_text.strip() # value is already a string\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_regex(self):\n",
    "        # Get text\n",
    "        text = self.__get_parent_text()\n",
    "        \n",
    "        # Get regular expression pattern\n",
    "        pattern = self.__parent_command.get(\"pattern\")\n",
    "        if pattern is None:\n",
    "            raise TrackingScraperError(\"No regular expression found\")\n",
    "        \n",
    "        # Match expression with text\n",
    "        regex    = re.search(pattern, text)\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if regex is None:\n",
    "            logging.info(\"Regular expression does not match text, using required\")\n",
    "            return not required\n",
    "        \n",
    "        # Get list of matched elements\n",
    "        elements = list(regex.groups())\n",
    "        \n",
    "        # Get child command list and process them, if possible\n",
    "        commands = self.__parent_command.get(\"commands\")\n",
    "        if isinstance(commands, list):\n",
    "            return self.__process_child_commands(commands, elements)\n",
    "        \n",
    "        # If no single child command was found, return list of matched elements\n",
    "        return elements\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_save(self):\n",
    "        attribute = self.__parent_command.get(\"key\")\n",
    "        if attribute is None:\n",
    "            raise TrackingScraperError(\"Save key not found\")\n",
    "        \n",
    "        # If a value was already defined, save it and exit\n",
    "        value = self.__parent_command.get(\"value\")\n",
    "        if value is not None:\n",
    "            self.__document[attribute] = value\n",
    "            return True\n",
    "        \n",
    "        # Get text to be saved, and verify if it's not empty\n",
    "        value    = self.__get_parent_text()\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if len(value) == 0:\n",
    "            logging.info(\"Text to save is empty, using required\")\n",
    "            return not required\n",
    "        \n",
    "        # Format type if necessary\n",
    "        format_type = self.__parent_command.get(\"format\")\n",
    "        if format_type is not None:\n",
    "            value = TrackingScraperConverter(value, format_type, self.__configuration).convert()\n",
    "        \n",
    "        #  Save according to parent key and formatting value\n",
    "        self.__document[attribute] = value\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_compare(self):\n",
    "        # Get text to compare\n",
    "        text = self.__get_parent_text()\n",
    "        \n",
    "        # Get values to compare\n",
    "        values = self.__parent_command.get(\"values\")\n",
    "        if values is not None:\n",
    "            raise TrackingScraperError(\"Values to compare not found\")\n",
    "        \n",
    "        # Check if text equals to value, or if it is in value list, then act accordingly\n",
    "        if text in values:\n",
    "            commands = self.__parent_command.get(\"success\")\n",
    "            return self.__process_compare_commands(commands, \"Success\")\n",
    "        else:\n",
    "            commands = self.__parent_command.get(\"failure\")\n",
    "            return self.__process_compare_commands(commands, \"Failure\")\n",
    "    \n",
    "    def __process_compare_commands(self, commands, compare_result):\n",
    "        # Check requirements\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if commands is None:\n",
    "            logging.info(compare_result + \" commands not found, resorting to required\")\n",
    "            return not required\n",
    "        \n",
    "        # Process child commands\n",
    "        for child_command in commands:\n",
    "            result = self.__generate_child_process(child_command, self.__parent_element)\n",
    "            if result is not True:\n",
    "                return result\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_write(self):\n",
    "        # Get value\n",
    "        value = self.__parent_command.get(\"value\")\n",
    "        if value is None:\n",
    "            # Get value from attribute\n",
    "            attribute = self.__parent_command.get(\"attribute\")\n",
    "            if attribute is None:\n",
    "                raise TrackingScraperError(\"No value or attribute to use as input\")\n",
    "            value = self.__document.get(attribute)\n",
    "        \n",
    "        try:\n",
    "            # Clear element if specified\n",
    "            if self.__parent_command.get(\"clean\", TrackingScraperConfig.DEFAULT_KEY_CLEAN):\n",
    "                self.__parent_element.clear()\n",
    "            # Write value\n",
    "            self.__parent_element.send_keys(value)\n",
    "            # Send enter if specified\n",
    "            if self.__parent_command.get(\"enter\", TrackingScraperConfig.DEFAULT_KEY_ENTER):\n",
    "                self.__parent_element.send_keys(Keys.ENTER)\n",
    "        except AttributeError:\n",
    "            raise TrackingScraperError(\"Element is not interactable (attribute)\")\n",
    "        except ElementNotInteractableException:\n",
    "            raise TrackingScraperError(\"Element is not interactable (selenium)\")\n",
    "        \n",
    "        # Return True to indicate everything is OK\n",
    "        time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_alert(self):\n",
    "        assertion = self.__parent_command.get(\"assertion\")\n",
    "        try:\n",
    "            # Try to switch to alert\n",
    "            alert = self.__driver.switch_to.alert\n",
    "            if assertion is False:\n",
    "                raise TrackingScraperError(\"Assertion failed: Alert unexpectedly found\")\n",
    "            # Accept or dismiss action depending on command\n",
    "            if self.__parent_command.get(\"action\", TrackingScraperConfig.DEFAULT_KEY_ACTION):\n",
    "                alert.accept()\n",
    "            else:\n",
    "                alert.dismiss()\n",
    "        except NoAlertPresentException:\n",
    "            if assertion is True:\n",
    "                raise TrackingScraperError(\"Assertion failed: Alert unexpectedly not found\")\n",
    "        \n",
    "        # Return True to indicate everything is OK\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_click(self):\n",
    "        # Check requirements\n",
    "        required = self.__parent_command.get(\"required\", TrackingScraperConfig.DEFAULT_KEY_REQUIRED)\n",
    "        if not self.__parent_element.is_displayed():\n",
    "            return not required\n",
    "        if not self.__parent_element.is_enabled():\n",
    "            return not required\n",
    "        \n",
    "        try:\n",
    "            # Try to click the element\n",
    "            self.__parent_element.click()\n",
    "            \n",
    "            # Wait 2 or 5 seconds depending on \"wait\" attribute\n",
    "            wait_time = self.__parent_command.get(\"wait\", TrackingScraperConfig.DEFAULT_KEY_WAIT)\n",
    "            if wait_time:\n",
    "                time.sleep(TrackingScraperConfig.DEFAULT_WAIT_LONG)\n",
    "            else:\n",
    "                time.sleep(TrackingScraperConfig.DEFAULT_WAIT_SHORT)\n",
    "                \n",
    "            # Return True to indicate everything is OK\n",
    "            return True\n",
    "        except ElementNotInteractableException:\n",
    "            return not required\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _process_ocr(self):\n",
    "        length = self.__parent_command.get(\"length\")\n",
    "        if length is None:\n",
    "            raise TrackingScraperError(\"Text length not defined\")\n",
    "        \n",
    "        # Request text\n",
    "        text = input(\"Enter captcha text: \")\n",
    "        if len(text) != length:\n",
    "            raise TrackingScraperError(\"Text is not \" + length + \" characters long\")\n",
    "        \n",
    "        # Save to attribute\n",
    "        self.__document[\"ocr\"] = text\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraperConverter:\n",
    "    \"\"\"Utility class to convert text to other Python types.\"\"\"\n",
    "    \n",
    "    def __init__(self, raw_text, format_type, configuration):\n",
    "        self.__raw_text      = raw_text\n",
    "        self.__format_type   = format_type\n",
    "        self.__configuration = configuration\n",
    "    \n",
    "    def convert(self):\n",
    "        \"\"\"Try to convert to the desired type, if none found, return text as-is.\"\"\"\n",
    "        try:\n",
    "            method = getattr(self, \"_convert_to_\" + self.__format_type)\n",
    "            return method()\n",
    "        except AttributeError:\n",
    "            logging.info(\"Convertion to \" + self.__format_type + \" not supported, resorting to text\")\n",
    "            return self.__raw_text\n",
    "        except TypeError:\n",
    "            raise TrackingScraperError(\"Convertion to \" + self.__format_type + \" cannot be invoked\")\n",
    "    \n",
    "    def _convert_to_int(self):\n",
    "        \"\"\"Convert text to an integer.\"\"\"\n",
    "        try:\n",
    "            return int(self.__raw_text.replace(TrackingScraperConfig.DEFAULT_THOUSAND_SYMBOL, \"\"))\n",
    "        except ValueError:\n",
    "            logging.info(\"Convertion to integer failed, resorting to text\")\n",
    "            return self.__raw_text\n",
    "    \n",
    "    def _convert_to_float(self):\n",
    "        \"\"\"Convert text to a double-precision floating-point number.\"\"\"\n",
    "        try:\n",
    "            return float(self.__raw_text.replace(TrackingScraperConfig.DEFAULT_THOUSAND_SYMBOL, \"\"))\n",
    "        except ValueError:\n",
    "            logging.info(\"Convertion to float failed, resorting to text\")\n",
    "            return self.__raw_text\n",
    "    \n",
    "    def _convert_to_double(self):\n",
    "        # Alias for self._convert_to_float().\n",
    "        return self._convert_to_float()\n",
    "    \n",
    "    def _convert_to_datetime(self):\n",
    "        \"\"\"Convert text to a Python datetime object.\"\"\"\n",
    "        # Get datetime patterns\n",
    "        try:\n",
    "            patterns = self.__configuration[\"general\"][\"datetimes\"]\n",
    "        except KeyError:\n",
    "            logging.info(\"Datetime patterns not found, resorting to text\")\n",
    "            return self.__raw_text\n",
    "        \n",
    "        # Try each pattern until it matches one\n",
    "        for pattern in patterns:\n",
    "            try:\n",
    "                return datetime.strptime(self.__raw_text, pattern)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # If none of the patterns matched, return text as-is\n",
    "        logging.info(\"None of the patterns matched, resorting to text\")\n",
    "        return self.__raw_text\n",
    "    \n",
    "    def _convert_to_date(self):\n",
    "        \"\"\"Convert text to a Python date object.\"\"\"\n",
    "        value = self._convert_to_datetime()\n",
    "        if isinstance(value, datetime):\n",
    "            return value.date()\n",
    "        return value\n",
    "    \n",
    "    def _convert_to_time(self):\n",
    "        \"\"\"Convert text to a Python time object.\"\"\"\n",
    "        value = self._convert_to_datetime()\n",
    "        if isinstance(value, datetime):\n",
    "            return value.time()\n",
    "        return value\n",
    "    \n",
    "    def _convert_to_local_datetime(self):\n",
    "        \"\"\"Convert text to a Python datetime object taking the defined locale into account.\"\"\"\n",
    "        value = self._convert_to_datetime()\n",
    "        if isinstance(value, datetime):\n",
    "            return value - timedelta(**TrackingScraperConfig.DEFAULT_DATETIME_LOCALE)\n",
    "        return value\n",
    "    \n",
    "    def _convert_to_local_time(self):\n",
    "        \"\"\"Convert text to a Python time object taking the defined locale into account.\"\"\"\n",
    "        value = self._convert_to_local_datetime()\n",
    "        if isinstance(value, datetime):\n",
    "            return value.time()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main scraper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingScraper:\n",
    "    \"\"\"Main class for the Tracking Web Scraper.\"\"\"\n",
    "    \n",
    "    def __init__(self, document):\n",
    "        self.__document = document\n",
    "        \n",
    "        # Initialize WebDriver\n",
    "        try:\n",
    "            self.__driver = webdriver.Chrome(executable_path = \"../driver/chromedriver\")\n",
    "        except WebDriverException as ex:\n",
    "            raise TrackingScraperError(\"Error creating Selenium driver. \" + str(ex))\n",
    "            \n",
    "        # Get configuration file\n",
    "        try:\n",
    "            with open(\"../config/\" + self.__document[\"carrier\"] + \".json\") as file:\n",
    "                self.__configuration = json.load(file)\n",
    "        except KeyError:\n",
    "            self.__driver.close()\n",
    "            raise TrackingScraperError(\"Carrier not found\")\n",
    "        except FileNotFoundError:\n",
    "            self.__driver.close()\n",
    "            raise TrackingScraperError(\"Configuration file not found\")\n",
    "        except json.JSONDecodeError as ex:\n",
    "            self.__driver.close()\n",
    "            raise TrackingScraperError(\"Configuration file could not be read: \" + str(ex))\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def execute(self):\n",
    "        parent_result   = False\n",
    "        input_result    = False\n",
    "        single_result   = False\n",
    "        multiple_result = False\n",
    "        \n",
    "        try:\n",
    "            start = self._go_to_url()\n",
    "            while True:\n",
    "                # Check if we're still on time\n",
    "                end = time.time()\n",
    "                if (end - start) > TrackingScraperConfig.DEFAULT_TIMEOUT:\n",
    "                    raise TrackingScraperError(\"Timeout exceeded, scraping was unsuccessful\")\n",
    "                \n",
    "                # Execute input\n",
    "                input_result = self._execute_commands(input_result, \"input\")\n",
    "                if input_result is not True:\n",
    "                    logging.info(\"Input execution was unsuccessful, retrying...\")\n",
    "                    continue\n",
    "                \n",
    "                # Execute single output\n",
    "                single_result = self._execute_commands(single_result, \"single\")\n",
    "                if single_result is not True:\n",
    "                    logging.info(\"Single output execution was unsuccessful, retrying...\")\n",
    "                    continue\n",
    "                \n",
    "                # Execute multiple output\n",
    "                multiple_result = self._execute_multiple_output(multiple_result)\n",
    "                if multiple_result is not True:\n",
    "                    logging.info(\"Multiple output execution was unsuccessful, retrying...\")\n",
    "                    continue\n",
    "                \n",
    "                # Return True if everything executed correctly\n",
    "                parent_result = True\n",
    "                break\n",
    "        finally:\n",
    "            self.__driver.close()\n",
    "            return parent_result\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _go_to_url(self):\n",
    "        try:\n",
    "            link = self.__configuration[\"general\"][\"url\"]\n",
    "            self.__driver.get(link.format(**self.__document))\n",
    "            time.sleep(TrackingScraperConfig.DEFAULT_WAIT_LONG)\n",
    "        except KeyError:\n",
    "            raise TrackingScraperError(\"Configuration URL could not be found\")\n",
    "        except TimeoutException:\n",
    "            raise TrackingScraperError(\"Error loading Web page, timeout exceeded\")\n",
    "        \n",
    "        # Start time\n",
    "        return time.time()\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _execute_commands(self, parent_result, key):\n",
    "        # Check if commands were already executed\n",
    "        if parent_result is True:\n",
    "            return True\n",
    "        \n",
    "        # Get commands, if none found, return True\n",
    "        commands = self.__configuration.get(key)\n",
    "        if commands is None:\n",
    "            return True\n",
    "        \n",
    "        # Process parent commands\n",
    "        for command in commands:\n",
    "            result = TrackingScraperSwitcher(self.__driver, self.__document, self.__configuration,\n",
    "                                             command).process()\n",
    "            if result is not True:\n",
    "                return False\n",
    "        \n",
    "        # Return True if everything was OK\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _execute_multiple_output(self, multiple_result):\n",
    "        if multiple_result is True:\n",
    "            return True\n",
    "        \n",
    "        # Get multiple command, if none found, return True\n",
    "        multiple = self.__configuration.get(\"multiple\")\n",
    "        if multiple is None:\n",
    "            return True\n",
    "        \n",
    "        # Overwrite previous tracking items, if necessary\n",
    "        if multiple_node.get(\"overwrite\", TrackingScraperConfig.DEFAULT_KEY_OVERWRITE):\n",
    "            self.__document[\"tracking\"] = []\n",
    "        \n",
    "        # Generate and process multiple documents\n",
    "        multiple_document = {}\n",
    "        return self.__iterate_multiple_elements(multiple_command, multiple_document)\n",
    "    \n",
    "    def __iterate_multiple_elements(self, multiple_command, multiple_document = {},\n",
    "                                   previous_element = None):\n",
    "        # Get single commands\n",
    "        multiple_single_commands = multiple_command.get(\"single\")\n",
    "        if not isinstance(multiple_single_commands, list):\n",
    "            raise TrackingScraperError(\"Multiple command must have single commands key\")\n",
    "        \n",
    "        # Get parent elements, if none found, use driver to extract single commands\n",
    "        multiple_parents = multiple_command.get(\"parents\")\n",
    "        if multiple_parents is None:\n",
    "            multiple_elements = [self.__driver]\n",
    "        else:\n",
    "            multiple_elements = TrackingScraperSwitcher(self.__driver, {}, self.__configuration,\n",
    "                                                        multiple_parents, previous_element)\n",
    "            if not isinstance(multiple_elements, list):\n",
    "                raise TrackingScraperError(\"Parent elements must be a list of web elements\")\n",
    "        \n",
    "        # Iterate through multiple elements\n",
    "        # (driver, document, configuration, parent_command, parent_element = None)\n",
    "        for element in multiple_elements:\n",
    "            result = TrackingScraperSwitcher(self.__driver, multiple_document,\n",
    "                                             self.__configuration, child_command)\n",
    "            if result is not True:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    ###############################################################################################\n",
    "    \n",
    "    def _insert_or_update(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = {\n",
    "    \"year\": \"test\",\n",
    "    \"manifest\": \"test\",\n",
    "    \"detail\": \"test\",\n",
    "    \"container\": \"EGSU9089973\",\n",
    "    \"carrier\": \"Evergreen\"\n",
    "}\n",
    "\n",
    "# Hapag-Lloyd: FSCU5670046, HLXU5183586\n",
    "# Maersk: MAEU6835658\n",
    "# Evergreen: EGSU9089973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter captcha text: LQTB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    scraper = TrackingScraper(container)\n",
    "    scraper.execute()\n",
    "    print(\"Finished\")\n",
    "except TrackingScraperError:\n",
    "    logging.exception(\"Exception ocurred\")\n",
    "    print(\"Finished with errors\")\n",
    "except Exception:\n",
    "    logging.exception(\"Unknown exception ocurred\")\n",
    "    print(\"Finished with unknown exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carrier': 'Evergreen',\n",
       " 'container': 'EGSU9089973',\n",
       " 'detail': 'test',\n",
       " 'estimated_arrival': datetime.date(2019, 4, 11),\n",
       " 'manifest': 'test',\n",
       " 'ocr': 'LQTB',\n",
       " 'type': \"40'(SH)\",\n",
       " 'vessel_voyage': 'EVER LAMBENT 0403-037W',\n",
       " 'year': 'test'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
